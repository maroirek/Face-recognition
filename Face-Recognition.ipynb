{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is a machine learning algorithm to recognise faces that figure in the training data (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # provides functions to interact with the operating system\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import cv2 as cv \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Loading images that will be used as dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Face_recognition_base= os.path.dirname(os.path.abspath('Face-Recognition.ipynb')) # define the path to our base\n",
    "Face_recognition_images = os.path.join(Face_recognition_base,\"Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Create the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21379\\AppData\\Local\\Temp\\ipykernel_12284\\43559983.py:25: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  res_img= pil_im.resize((500,500), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "x_train=[]\n",
    "y_labels=[]\n",
    "id=0\n",
    "face_casc = cv.CascadeClassifier('cascades/haarcascade_frontalface_alt2.xml') # Algorithm of face detection (Haar Cascade)\n",
    "\n",
    "for root, dirs, images in os.walk(Face_recognition_images):\n",
    "    for image in images :\n",
    "        if image.endswith('png') or image.endswith('jpg') :\n",
    "            path= os.path.join(root, image)\n",
    "            label = os.path.basename(os.path.dirname(path)) # get labels that are the names of the directories\n",
    "            # label = os.path.basename(root) // same as the previous line\n",
    "            # Note : we need to make sure that each directory represents a label and it is an attached name (no spaces in it)\n",
    "     \n",
    "# Creation of the dictionnary containing faces labels and their identifiers (labels should be numbers not str)       \n",
    "            if not (label in labels) :\n",
    "                labels.append(label)\n",
    "            label_id = {labels[i]: list(range(len(labels)))[i] for i in range(len(labels))}\n",
    "              \n",
    "                                           \n",
    "# we will convert our images into arrays: \n",
    "            pil_im=Image.open(path).convert('L') # convert into grayscale cuz we need it in gray scale\n",
    "            \n",
    "            # after training data, the accuracy of the model was bad, so will resize images to work with identical ones.\n",
    "            res_img= pil_im.resize((500,500), Image.ANTIALIAS)\n",
    "            \n",
    "            \n",
    "            \n",
    "            np_im=np.array(res_img, dtype='uint8')  # uint8 variable format for pixels\n",
    "\n",
    "            faces= face_casc.detectMultiScale(np_im, scaleFactor=1.5, minNeighbors=5) \n",
    "            # the classifier accepts only np arrays, cv2 manipulates images as arrays not like pillow, so we don't need to convert\n",
    "            for(x,y,w,h) in faces : \n",
    "                x_train.append(np_im[y:y+h,x:x+h])\n",
    "                y_labels.append(label_id[label])\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the images with their labels as a dataset (convert labels to binary format)\n",
    "\n",
    "with open('labels.pickle','wb') as f :    # 'wb' w write in the file and b byte, labels.pickle c l nom du file\n",
    "    pickle.dump(label_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of the recogniser\n",
    "\n",
    "recog= cv.face.LBPHFaceRecognizer_create()\n",
    "recog.train(x_train,np.array(y_labels))\n",
    "recog.save('trainner.yml')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Prediction  (can be in a completely different python file if we have the trainner.yml file and we know what recognizer we chose 'LBPH in our case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog.read('trainner.yml')   #once the recognizer is trained. we can use it to predict without train it \n",
    "                             #(model pres entaine) just we read the training file associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Label names from pickle\n",
    "\n",
    "from cv2 import LINE_AA\n",
    "\n",
    "\n",
    "Labelstest={}\n",
    "with open('labels.pickle','rb') as f :   \n",
    "    orig_Labelstest = pickle.load(f)\n",
    "    inv_label={ v:k for k,v in orig_Labelstest.items() }  # we need to invert names and ids cuz the prediction gives us\n",
    "                                                          # number and we have to get names\n",
    "\n",
    "# testing on video capture \n",
    "\n",
    "cap = cv.VideoCapture(0)   # 0 for laptop camera\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)   # This kind of cascade classifier works only on gray images\n",
    "    faces= face_casc.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "    for(x,y,w,h) in faces : \n",
    "        \n",
    "        id_, conf = recog.predict(gray[y:y+h, x:x+h])\n",
    "        if conf>45 and conf<85:          # we need to check the signification of conf !\n",
    "            cv.putText(frame, inv_label[id_], (x,y), cv.FONT_HERSHEY_SIMPLEX, int('1'), (255,0,0), int('2'), cv.LINE_AA)\n",
    "            \n",
    "        cv.imshow('frame', frame)\n",
    "        \n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why the recognizer doesn't give the correct results may be the size of images, we didn't use identical size images so that can cause a problem in the prediction by next cuz the training was not that good. So we changed the data size, we need to garantee that we have good data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                          \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9465493d991c10192be70692998c1f839aa44a98ea441dac77f59407aba251ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
